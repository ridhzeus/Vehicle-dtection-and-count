{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoPKoQD3JCtC"
      },
      "outputs": [],
      "source": [
        "pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # This will prompt you to upload kaggle.json"
      ],
      "metadata": {
        "id": "ODV8CaKmL3J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle\\ \\(1\\).json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json  # Set correct permissions"
      ],
      "metadata": {
        "id": "2bgTGP6hMhMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c ultrasound-nerve-segmentation"
      ],
      "metadata": {
        "id": "oaITJUy0Mibl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "guZ5Dr_zM5dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(43)\n",
        "np.random.seed(43)"
      ],
      "metadata": {
        "id": "NpuK5p_TM8fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ultrasound-nerve-segmentation.zip -d ultrasound_nerve_segmentation"
      ],
      "metadata": {
        "id": "wHzZEggQNkiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path = \"ultrasound_nerve_segmentation/train/\"  # Ensure this matches the extracted directory\n",
        "file_list = os.listdir(path)\n",
        "file_list[:20]"
      ],
      "metadata": {
        "id": "vgF65hl3Nw1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image = []\n",
        "train_mask = glob(path + '*_mask*')\n",
        "\n",
        "for i in train_mask:\n",
        "    train_image.append(i.replace('_mask', ''))\n",
        "\n",
        "print(train_image[:10],\"\\n\" ,train_mask[:10])"
      ],
      "metadata": {
        "id": "0mxb-gYnN2Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image1 = np.array(Image.open(path+\"1_1.tif\"))\n",
        "image1_mask = np.array(Image.open(path+\"1_1_mask.tif\"))\n",
        "image1_mask = np.ma.masked_where(image1_mask == 0, image1_mask)\n",
        "\n",
        "fig, ax = plt.subplots(1,3,figsize = (16,12))\n",
        "ax[0].imshow(image1, cmap = 'gray')\n",
        "\n",
        "ax[1].imshow(image1_mask, cmap = 'gray')\n",
        "\n",
        "ax[2].imshow(image1, cmap = 'gray', interpolation = 'none')\n",
        "ax[2].imshow(image1_mask, cmap = 'jet', interpolation = 'none', alpha = 0.7)\n"
      ],
      "metadata": {
        "id": "aoRbisxxN3bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width = 128\n",
        "height = 128"
      ],
      "metadata": {
        "id": "RMPXOxonN_et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate,add\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.losses import binary_crossentropy, MSE"
      ],
      "metadata": {
        "id": "TvdNPGxQOEXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred, smooth = 1.0):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def iou(y_true, y_pred, smooth = 1.0):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum ( y_true_f * y_pred_f) + smooth\n",
        "    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f) + smooth\n",
        "\n",
        "    return intersection/union\n",
        "\n",
        "def iou_loss(y_true, y_pred):\n",
        "    return 1 - iou(y_true, y_pred)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def bbox_loss(y_true, y_pred):\n",
        "    y_cls = K.sum(y_true, axis=-1)\n",
        "\n",
        "    loss = K.mean(K.square(y_true - y_pred), axis=-1)\n",
        "    loss = loss * y_cls\n",
        "    return loss\n",
        "\n",
        "def cgm_loss(y_true, y_pred):\n",
        "    y_tr_cls = y_true[:, 0]\n",
        "    y_tr_bb = y_true[:, 1:]\n",
        "    y_pr_cls = y_pred[:, 0]\n",
        "    y_pr_bb = y_pred[:, 1:]\n",
        "\n",
        "    return binary_crossentropy(y_tr_cls, y_pr_cls) + MSE(y_tr_bb, y_pr_bb) * y_tr_cls\n",
        "\n",
        "# From : https://github.com/symoon94/YOLO-keras/blob/master/yolo2/loss.py\n",
        "def box_diou(b_true, b_pred):\n",
        "    \"\"\"\n",
        "    Calculate DIoU/CIoU loss on anchor boxes\n",
        "    Reference Paper:\n",
        "        \"Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression\"\n",
        "        https://arxiv.org/abs/1911.08287\n",
        "    Parameters\n",
        "    ----------\n",
        "    b_true: GT boxes tensor, shape=(batch, feat_w, feat_h, anchor_num, 4), xywh\n",
        "    b_pred: predict boxes tensor, shape=(batch, feat_w, feat_h, anchor_num, 4), xywh\n",
        "    use_ciou: bool flag to indicate whether to use CIoU loss type\n",
        "    Returns\n",
        "    -------\n",
        "    diou: tensor, shape=(batch, feat_w, feat_h, anchor_num, 1)\n",
        "    \"\"\"\n",
        "    b_true_xy = b_true[:, :2]\n",
        "    b_true_wh = b_true[:, 2:4]\n",
        "    b_true_wh_half = b_true_wh/2.\n",
        "    b_true_mins = b_true_xy - b_true_wh_half\n",
        "    b_true_maxes = b_true_xy + b_true_wh_half\n",
        "\n",
        "    b_pred_xy = b_pred[:, :2]\n",
        "    b_pred_wh = b_pred[:, 2:4]\n",
        "    b_pred_wh_half = b_pred_wh/2.\n",
        "    b_pred_mins = b_pred_xy - b_pred_wh_half\n",
        "    b_pred_maxes = b_pred_xy + b_pred_wh_half\n",
        "\n",
        "    intersect_mins = K.maximum(b_true_mins, b_pred_mins)\n",
        "    intersect_maxes = K.minimum(b_true_maxes, b_pred_maxes)\n",
        "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_area = intersect_wh[:, 0] * intersect_wh[:, 1]\n",
        "    b_true_area = b_true_wh[:, 0] * b_true_wh[:, 1]\n",
        "    b_pred_area = b_pred_wh[:, 0] * b_pred_wh[:, 1]\n",
        "    union_area = b_true_area + b_pred_area - intersect_area\n",
        "    # calculate IoU, add epsilon in denominator to avoid dividing by 0\n",
        "    iou = intersect_area / (union_area + K.epsilon())\n",
        "\n",
        "    # box center distance\n",
        "    center_distance = K.sum(K.square(b_true_xy - b_pred_xy), axis=-1)\n",
        "    # get enclosed area\n",
        "    enclose_mins = K.minimum(b_true_mins, b_pred_mins)\n",
        "    enclose_maxes = K.maximum(b_true_maxes, b_pred_maxes)\n",
        "    enclose_wh = K.maximum(enclose_maxes - enclose_mins, 0.0)\n",
        "    # get enclosed diagonal distance\n",
        "    enclose_diagonal = K.sum(K.square(enclose_wh), axis=-1)\n",
        "    # calculate DIoU, add epsilon in denominator to avoid dividing by 0\n",
        "    diou = iou - 1.0 * (center_distance) / (enclose_diagonal + K.epsilon())\n",
        "\n",
        "    return diou"
      ],
      "metadata": {
        "id": "NNsqp9GlOJ3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_mask = []\n",
        "pos_img = []\n",
        "neg_mask = []\n",
        "neg_img = []\n",
        "\n",
        "for mask_path, img_path in zip(train_mask, train_image):\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if np.sum(mask) == 0:\n",
        "        neg_mask.append(mask_path)\n",
        "        neg_img.append(img_path)\n",
        "    else:\n",
        "        pos_mask.append(mask_path)\n",
        "        pos_img.append(img_path)"
      ],
      "metadata": {
        "id": "WzZYLM8DON5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir generated\n",
        "!mkdir generated/img"
      ],
      "metadata": {
        "id": "EfiffcIUOS0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flip_up_down(img):\n",
        "    newImg = img.copy()\n",
        "    return cv2.flip(newImg, 0)\n",
        "\n",
        "def flip_right_left(img):\n",
        "    newImg = img.copy()\n",
        "    return cv2.flip(newImg, 1)"
      ],
      "metadata": {
        "id": "7MotxhzXOUyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_img = []\n",
        "gen_mask = []\n",
        "\n",
        "for (img_path, mask_path) in tqdm(zip(pos_img, pos_mask)):\n",
        "    image_name = img_path.split('/')[-1].split('.')[0]\n",
        "\n",
        "    uf_img_path = 'generated/img/'+image_name+'_uf.jpg'\n",
        "    uf_mask_path = 'generated/img/'+image_name+'_uf_mask.jpg'\n",
        "    rf_img_path = 'generated/img/'+image_name+'_rf.jpg'\n",
        "    rf_mask_path = 'generated/img/'+image_name+'_rf_mask.jpg'\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    mask = cv2.imread(mask_path)\n",
        "\n",
        "    uf_img = flip_up_down(img)\n",
        "    uf_mask = flip_up_down(mask)\n",
        "    cv2.imwrite(uf_img_path, uf_img)\n",
        "    cv2.imwrite(uf_mask_path, uf_mask)\n",
        "\n",
        "    rf_img = flip_right_left(img)\n",
        "    rf_mask = flip_right_left(mask)\n",
        "    cv2.imwrite(rf_img_path, rf_img)\n",
        "    cv2.imwrite(rf_mask_path, rf_mask)\n",
        "\n",
        "    gen_img.append(uf_img_path)\n",
        "    gen_mask.append(uf_mask_path)\n",
        "    gen_img.append(rf_img_path)\n",
        "    gen_mask.append(rf_mask_path)"
      ],
      "metadata": {
        "id": "yvETz72eOZLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intruders = []\n",
        "\n",
        "try:\n",
        "    with open('intruders.dat', 'rb') as f:\n",
        "        intruders = pickle.load(f)\n",
        "except FileNotFoundError:\n",
        "    pos_images = np.array([cv2.imread(i, cv2.IMREAD_GRAYSCALE) for i in pos_img])\n",
        "\n",
        "    for im_path in tqdm(neg_img):\n",
        "        neg = cv2.imread(im_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        comp = pos_images == neg\n",
        "        for i, j in enumerate(comp):\n",
        "            if j.all():\n",
        "                # print(im_path.replace('\\\\', '\\\\\\\\'))\n",
        "                intruders.append(im_path)\n",
        "                break\n",
        "\n",
        "    with open('intruders.dat', 'wb') as f:\n",
        "        pickle.dump(intruders, f)"
      ],
      "metadata": {
        "id": "c6IcwtvPOjpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Throwing away False Negative from dataset\n",
        "\n",
        "train_image_polished = train_image.copy()\n",
        "train_mask_polished = train_mask.copy()\n",
        "\n",
        "for i in intruders:\n",
        "    index = train_image.index(i)\n",
        "    train_image_polished.pop(index)\n",
        "    train_mask_polished.pop(index)"
      ],
      "metadata": {
        "id": "AKcUcgEtRhCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_img = gen_img + train_image_polished\n",
        "aug_mask = gen_mask + train_mask_polished\n",
        "\n",
        "df_ = pd.DataFrame(data={\"filename\": aug_img, 'mask' : aug_mask})\n",
        "df = df_.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "kf = KFold(n_splits = 5, shuffle=False)"
      ],
      "metadata": {
        "id": "UqyePcPKRl5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "def res_block(inputs,filter_size):\n",
        "    \"\"\"\n",
        "    res_block -- Residual block for building res path\n",
        "\n",
        "    Arguments:\n",
        "    inputs {<class 'tensorflow.python.framework.ops.Tensor'>} -- input for residual block\n",
        "    filter_size {int} -- convolutional filter size\n",
        "\n",
        "    Returns:\n",
        "    add {<class 'tensorflow.python.framework.ops.Tensor'>} -- addition of two convolutional filter output\n",
        "    \"\"\"\n",
        "    # First Conv2D layer\n",
        "    cb1 = Conv2D(filter_size,(3,3),padding = 'same',activation=\"relu\")(inputs)\n",
        "    # Second Conv2D layer parallel to the first one\n",
        "    cb2 = Conv2D(filter_size,(1,1),padding = 'same',activation=\"relu\")(inputs)\n",
        "    # Addition of cb1 and cb2\n",
        "    add = Add()([cb1,cb2])\n",
        "\n",
        "    return add\n",
        "\n",
        "# def res_path(inputs,filter_size,path_number):\n",
        "#     \"\"\"\n",
        "#     res_path -- residual path / modified skip connection\n",
        "\n",
        "#     Arguments:\n",
        "#     inputs {<class 'tensorflow.python.framework.ops.Tensor'>} -- input for res path\n",
        "#     filter_size {int} -- convolutional filter size\n",
        "#     path_number {int} -- path identifier\n",
        "\n",
        "#     Returns:\n",
        "#     skip_connection {<class 'tensorflow.python.framework.ops.Tensor'>} -- final res path\n",
        "#     \"\"\"\n",
        "#     # Minimum one residual block for every res path\n",
        "#     skip_connection = res_block(inputs, filter_size)\n",
        "\n",
        "#     # Two serial residual blocks for res path 2\n",
        "#     if path_number == 2:\n",
        "#         skip_connection = res_block(skip_connection,filter_size)\n",
        "\n",
        "#     # Three serial residual blocks for res path 1\n",
        "#     elif path_number == 1:\n",
        "#         skip_connection = res_block(skip_connection,filter_size)\n",
        "#         skip_connection = res_block(skip_connection,filter_size)\n",
        "\n",
        "#     return skip_connection\n",
        "\n",
        "def decoder_block(inputs, out_channels, depth):\n",
        "\n",
        "    \"\"\"\n",
        "    decoder_block -- decoder block formation\n",
        "\n",
        "    Arguments:\n",
        "    inputs {<class 'tensorflow.python.framework.ops.Tensor'>} -- input for decoder block\n",
        "    mid_channels {int} -- no. of mid channels\n",
        "    out_channels {int} -- no. of out channels\n",
        "\n",
        "    Returns:\n",
        "    db {<class 'tensorflow.python.framework.ops.Tensor'>} -- returning the decoder block\n",
        "    \"\"\"\n",
        "    conv_kwargs = dict(\n",
        "        activation='relu',\n",
        "        padding='same',\n",
        "        kernel_initializer='he_normal',\n",
        "        data_format='channels_last'\n",
        "    )\n",
        "\n",
        "    # UpConvolutional layer\n",
        "    db = UpSampling2D((2, 2), interpolation='bilinear')(inputs)\n",
        "    #db = concatenate([db, res], axis=3)\n",
        "    # First conv2D layer\n",
        "    db = Conv2D(out_channels, 3, **conv_kwargs)(db)\n",
        "    # Second conv2D layer\n",
        "    db = Conv2D(out_channels, 3, **conv_kwargs)(db)\n",
        "\n",
        "    if depth > 2:\n",
        "        # Third conv2D layer\n",
        "        db = Conv2D(out_channels, 3, **conv_kwargs)(db)\n",
        "\n",
        "    return db\n",
        "\n",
        "def TransCGUNet(input_size=(512, 512, 1), pruned=False):\n",
        "    \"\"\"\n",
        "    TransResUNet -- main architecture of TransResUNet\n",
        "\n",
        "    Arguments:\n",
        "    input_size {tuple} -- size of input image\n",
        "\n",
        "    Returns:\n",
        "    model {<class 'tensorflow.python.keras.engine.training.Model'>} -- final model\n",
        "    \"\"\"\n",
        "\n",
        "    # Input\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # VGG16 with imagenet weights\n",
        "    encoder = VGG16(include_top=False, weights='imagenet', input_shape=input_size)\n",
        "\n",
        "    # First encoder block\n",
        "    enc1 = encoder.get_layer(name='block1_conv1')(inputs)\n",
        "    enc1 = encoder.get_layer(name='block1_conv2')(enc1)\n",
        "    enc2 = MaxPooling2D(pool_size=(2, 2))(enc1)\n",
        "\n",
        "    # Second encoder block\n",
        "    enc2 = encoder.get_layer(name='block2_conv1')(enc2)\n",
        "    enc2 = encoder.get_layer(name='block2_conv2')(enc2)\n",
        "    enc3 = MaxPooling2D(pool_size=(2, 2))(enc2)\n",
        "\n",
        "    # Third encoder block\n",
        "    enc3 = encoder.get_layer(name='block3_conv1')(enc3)\n",
        "    enc3 = encoder.get_layer(name='block3_conv2')(enc3)\n",
        "    enc3 = encoder.get_layer(name='block3_conv3')(enc3)\n",
        "    center = MaxPooling2D(pool_size=(2, 2))(enc3)\n",
        "\n",
        "    # Center block\n",
        "    center = Conv2D(512, (3, 3), activation='relu', padding='same', name='center1')(center)\n",
        "    center = Conv2D(512, (3, 3), activation='relu', padding='same', name='center2')(center)\n",
        "\n",
        "    # classification pred\n",
        "    cls = Conv2D(32, (3,3), activation='relu', padding='same')(center)\n",
        "    cls = Conv2D(1, (1,1))(cls)\n",
        "    cls = GlobalAveragePooling2D()(cls)\n",
        "    cls = Activation('sigmoid', name='class')(cls)\n",
        "    clsr = Reshape((1, 1, 1), name='reshape')(cls)\n",
        "\n",
        "    # Decoder block corresponding to third encoder\n",
        "    #res_path3 = res_path(enc3,128,3)\n",
        "    dec3 = decoder_block(center, 256, 3)\n",
        "\n",
        "    # Decoder block corresponding to second encoder\n",
        "    #res_path2 = res_path(enc2,64,2)\n",
        "    dec2 = decoder_block(dec3, 128, 2)\n",
        "\n",
        "    # Final Block concatenation with first encoded feature\n",
        "    #res_path1 = res_path(enc1,32,1)\n",
        "    dec1 = decoder_block(dec2, 64, 1)\n",
        "\n",
        "    # Output\n",
        "    out = Conv2D(1, 1)(dec1)\n",
        "    out = Activation('sigmoid', name='pre')(out)\n",
        "    out_2 = multiply(inputs=[out,clsr], name='seg')\n",
        "\n",
        "    # Final model\n",
        "    if pruned:\n",
        "        model = Model(inputs=[inputs], outputs=[out])\n",
        "    else:\n",
        "        model = Model(inputs=[inputs], outputs=[out_2, cls])\n",
        "        # Adding BBox\n",
        "        model = add_bbox(model)\n",
        "\n",
        "    return model\n",
        "\n",
        "def add_bbox(model):\n",
        "    # bbox branch\n",
        "    cls_ = Conv2D(256, (3,3), activation='relu', padding='same')(model.get_layer('center2').output)\n",
        "    cls_ = Conv2D(256, (3,3), activation='relu', padding='same')(cls_)\n",
        "    cls_ = MaxPooling2D(pool_size=(2, 2))(cls_)\n",
        "\n",
        "    cls_ = Conv2D(128, (3,3), activation='relu', padding='same')(cls_)\n",
        "    cls_ = Conv2D(128, (3,3), activation='relu', padding='same')(cls_)\n",
        "    cls_ = MaxPooling2D(pool_size=(2, 2))(cls_)\n",
        "\n",
        "    cls_ = Conv2D(64, (3,3), activation='relu', padding='same')(cls_)\n",
        "    cls_ = Conv2D(64, (3,3), activation='relu', padding='same')(cls_)\n",
        "    cls_ = MaxPooling2D(pool_size=(2, 2))(cls_)\n",
        "\n",
        "    cls_ = Conv2D(32, (3,3), activation='relu', padding='same')(cls_)\n",
        "    cls_ = Conv2D(32, (3,3), activation='relu', padding='same')(cls_)\n",
        "\n",
        "    bbox = Conv2D(4, (1,1))(cls_)\n",
        "    bbox = GlobalAveragePooling2D()(bbox)\n",
        "    bbox = Activation('sigmoid', name='bbox')(bbox)\n",
        "\n",
        "    return Model(inputs=[model.input], outputs=[model.output[0], model.output[1], bbox])"
      ],
      "metadata": {
        "id": "jKm5QequRsND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "def train_generator(data_frame, batch_size, train_path, aug_dict,\n",
        "        image_color_mode=\"rgb\",\n",
        "        mask_color_mode=\"grayscale\",\n",
        "        image_save_prefix=\"image\",\n",
        "        mask_save_prefix=\"mask\",\n",
        "        save_to_dir=None,\n",
        "        target_size=(256,256),\n",
        "        seed=1):\n",
        "    '''\n",
        "    can generate image and mask at the same time use the same seed for\n",
        "    image_datagen and mask_datagen to ensure the transformation for image\n",
        "    and mask is the same if you want to visualize the results of generator,\n",
        "    set save_to_dir = \"your path\"\n",
        "    '''\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "\n",
        "    image_generator = image_datagen.flow_from_dataframe(\n",
        "        data_frame,\n",
        "        directory = train_path,\n",
        "        x_col = \"filename\",\n",
        "        class_mode = None,\n",
        "        color_mode = image_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = image_save_prefix,\n",
        "        seed = seed)\n",
        "\n",
        "    mask_generator = mask_datagen.flow_from_dataframe(\n",
        "        data_frame,\n",
        "        directory = train_path,\n",
        "        x_col = \"mask\",\n",
        "        class_mode = None,\n",
        "        color_mode = mask_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = mask_save_prefix,\n",
        "        seed = seed)\n",
        "\n",
        "    train_gen = zip(image_generator, mask_generator)\n",
        "\n",
        "    for (img, mask) in train_gen:\n",
        "        img, mask, label, bbox = adjust_data(img, mask)\n",
        "        yield (img, [mask, label, bbox])\n",
        "\n",
        "def adjust_data(img,mask):\n",
        "    img = preprocess_input(img)\n",
        "\n",
        "    bbox = np.zeros((len(img), 4))\n",
        "    for i, m in enumerate(mask):\n",
        "        m_ = np.array(m, dtype='uint8')\n",
        "        _, thresh = cv2.threshold(m_,127,255,0)\n",
        "        contours, _ = cv2.findContours(thresh, 1, 2)\n",
        "        if len(contours) > 0:\n",
        "            cnt = contours[0]\n",
        "            x,y,w,h = cv2.boundingRect(cnt)\n",
        "\n",
        "            bbox[i, :] = x, y, w, h\n",
        "\n",
        "#     Assuming height == width\n",
        "    bbox /= height\n",
        "\n",
        "    mask = mask / 255\n",
        "    mask[mask > 0.5] = 1\n",
        "    mask[mask <= 0.5] = 0\n",
        "    masks_sum = np.sum(mask, axis=(1,2,3)).reshape((-1, 1))\n",
        "    class_lab = (masks_sum != 0) + 0.\n",
        "\n",
        "    return (img, mask, class_lab, bbox)"
      ],
      "metadata": {
        "id": "GS-CNEkpRxXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_img[0]"
      ],
      "metadata": {
        "id": "btQ9G7zeRygr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "histories = []\n",
        "losses = []\n",
        "accuracies = []\n",
        "dicecoefs = []\n",
        "ious = []\n",
        "\n",
        "train_generator_args = dict(rotation_range=0.2,\n",
        "                            width_shift_range=0.05,\n",
        "                            height_shift_range=0.05,\n",
        "                            shear_range=0.05,\n",
        "                            zoom_range=0.05,\n",
        "                            horizontal_flip=True,\n",
        "                            fill_mode='nearest')\n",
        "\n",
        "EPOCHS = 120\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "for k, (train_index, test_index) in enumerate(kf.split(df)):\n",
        "    print('\\nFold no. :', k+1)\n",
        "\n",
        "    train_data_frame = df.iloc[train_index]\n",
        "    test_data_frame = df.iloc[test_index]\n",
        "    #continue\n",
        "\n",
        "    train_gen = train_generator(train_data_frame, BATCH_SIZE,\n",
        "                                None,\n",
        "                                train_generator_args,\n",
        "                                target_size=(height, width))\n",
        "\n",
        "    test_gener = train_generator(test_data_frame, BATCH_SIZE,\n",
        "                                None,\n",
        "                                dict(),\n",
        "                                target_size=(height, width))\n",
        "\n",
        "    model = TransCGUNet(input_size=(height, width, 3))\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=1e-5),\n",
        "                    loss={'seg':dice_coef_loss, 'class':'binary_crossentropy', 'bbox':bbox_loss},\n",
        "                    loss_weights={'seg':1, 'class':1, 'bbox':1},\n",
        "                    metrics={'seg':[iou, dice_coef, 'binary_accuracy'], 'class':['accuracy'], 'bbox':['accuracy']})\n",
        "\n",
        "    model_checkpoint = ModelCheckpoint(str(k+1) + '_unet_ner_seg.hdf5',\n",
        "                                       verbose=1,\n",
        "                                       save_best_only=True)\n",
        "\n",
        "    history = model.fit(train_gen,\n",
        "                          steps_per_epoch=len(train_data_frame) // BATCH_SIZE,\n",
        "                          epochs=EPOCHS,\n",
        "                          callbacks=[model_checkpoint],\n",
        "                          validation_data = test_gener,\n",
        "                          validation_steps=len(test_data_frame) // BATCH_SIZE)\n",
        "\n",
        "    print('\\n\\nTesting the model. Fold :', (k+1), '\\n\\n')\n",
        "    model = load_model(str(k+1) + '_unet_ner_seg.hdf5',\n",
        "                       custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef, 'bbox_loss': bbox_loss})\n",
        "    test_gen = train_generator(test_data_frame, BATCH_SIZE,\n",
        "                                None,\n",
        "                                dict(),\n",
        "                                target_size=(height, width))\n",
        "    results = model.evaluate(test_gen, steps=len(test_data_frame) // BATCH_SIZE)\n",
        "    results = dict(zip(model.metrics_names,results))\n",
        "\n",
        "    histories.append(history)\n",
        "    accuracies.append(results['seg_seg_binary_accuracy'])\n",
        "    losses.append(results['seg_loss'])\n",
        "    dicecoefs.append(results['seg_seg_dice_coef'])\n",
        "    ious.append(results['seg_seg_iou'])\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "OVFs93K7R1II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "for h, history in enumerate(histories):\n",
        "\n",
        "    keys = history.history.keys()\n",
        "    fig, axs = plt.subplots(1, len(keys)//2, figsize = (25, 5))\n",
        "    fig.suptitle('No. ' + str(h+1) + ' Fold Results', fontsize=30)\n",
        "\n",
        "    for k, key in enumerate(list(keys)[:len(keys)//2]):\n",
        "        training = history.history[key]\n",
        "        validation = history.history['val_' + key]\n",
        "\n",
        "        epoch_count = range(1, len(training) + 1)\n",
        "\n",
        "        axs[k].plot(epoch_count, training, 'r--')\n",
        "        axs[k].plot(epoch_count, validation, 'b-')\n",
        "        axs[k].legend(['Training ' + key, 'Validation ' + key])\n",
        "\n",
        "    with open(str(h+1) + '_lungs_trainHistoryDict', 'wb') as file_pi:\n",
        "        pickle.dump(history.history, file_pi)"
      ],
      "metadata": {
        "id": "E5xRBo2KT6I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracies : ', accuracies)\n",
        "print('losses : ', losses)\n",
        "print('dicecoefs : ', dicecoefs)\n",
        "print('ious : ', ious)\n",
        "\n",
        "print('-----------------------------------------------------------------------------')\n",
        "print('-----------------------------------------------------------------------------')\n",
        "\n",
        "print('average accuracy : ', np.mean(np.array(accuracies)))\n",
        "print('average loss : ', np.mean(np.array(losses)))\n",
        "print('average dicecoefs : ', np.mean(np.array(dicecoefs)))\n",
        "print('average ious : ', np.mean(np.array(ious)))\n",
        "print()\n",
        "\n",
        "print('standard deviation of accuracy : ', np.std(np.array(accuracies)))\n",
        "print('standard deviation of loss : ', np.std(np.array(losses)))\n",
        "print('standard deviation of dicecoefs : ', np.std(np.array(dicecoefs)))\n",
        "print('standard deviation of ious : ', np.std(np.array(ious)))\n"
      ],
      "metadata": {
        "id": "BXUJt8jUXdUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    index=np.random.randint(0,len(test_data_frame.index))\n",
        "    print(i+1, index)\n",
        "    img = cv2.imread(test_data_frame['filename'].iloc[index])\n",
        "    img = cv2.resize(img, (height, width))\n",
        "    img = preprocess_input(img)\n",
        "    img = img[np.newaxis, :, :, :]\n",
        "    pred = model.predict(img)\n",
        "    pre_pred = Model(model.inputs, model.get_layer('pre').output).predict(img)\n",
        "\n",
        "    m_ = np.array(cv2.resize(cv2.imread(test_data_frame['mask'].iloc[index], cv2.IMREAD_GRAYSCALE), (height, width)), dtype='uint8')\n",
        "    _, thresh = cv2.threshold(m_,127,255,0)\n",
        "    contours, _ = cv2.findContours(thresh, 1, 2)\n",
        "\n",
        "    bbox = np.zeros(shape=4)\n",
        "    if len(contours) > 0:\n",
        "        cnt = contours[0]\n",
        "        x,y,w,h = cv2.boundingRect(cnt)\n",
        "\n",
        "        bbox[:] = x, y, w, h\n",
        "\n",
        "#     Assuming height == width\n",
        "    bbox /= height\n",
        "\n",
        "    plt.figure(figsize=(12,12))\n",
        "    plt.subplot(1,6,1)\n",
        "    plt.imshow(cv2.resize(cv2.imread(test_data_frame['filename'].iloc[index]), (height, width)))\n",
        "    plt.title('Original Image')\n",
        "    plt.subplot(1,6,2)\n",
        "    plt.imshow(np.squeeze(cv2.resize(cv2.imread(test_data_frame['mask'].iloc[index]), (height, width))))\n",
        "    plt.title('Original Mask')\n",
        "    plt.subplot(1,6,3)\n",
        "    plt.imshow(np.squeeze(pre_pred) > .5)\n",
        "    plt.title('Pre-Prediction')\n",
        "    plt.subplot(1,6,4)\n",
        "    plt.imshow(np.squeeze(pred[0]) > .5)\n",
        "    plt.title('Prediction')\n",
        "    x, y, w, h = np.array(bbox * height, dtype='int')\n",
        "    bb = cv2.resize(cv2.imread(test_data_frame['filename'].iloc[index], cv2.IMREAD_GRAYSCALE), (height, width))\n",
        "    bb = cv2.rectangle(bb, (x, y), (x+w, y+h), 1, 2)\n",
        "    plt.subplot(1,6,5)\n",
        "    plt.imshow(bb)\n",
        "    plt.title('BBox_original')\n",
        "    x, y, w, h = np.array(pred[2][0] * height, dtype='int')\n",
        "    print(pred[1],x,y,w,h)\n",
        "    bb = cv2.resize(cv2.imread(test_data_frame['filename'].iloc[index], cv2.IMREAD_GRAYSCALE), (height, width))\n",
        "    bb = cv2.rectangle(bb, (x, y), (x+w, y+h), 1, 2)\n",
        "    plt.subplot(1,6,6)\n",
        "    plt.imshow(bb)\n",
        "    plt.title('BBox')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "EwX-iwZebsZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracies : ', accuracies)\n",
        "print('losses : ', losses)\n",
        "print('dicecoefs : ', dicecoefs)\n",
        "print('ious : ', ious)\n",
        "\n",
        "print('-----------------------------------------------------------------------------')\n",
        "print('-----------------------------------------------------------------------------')\n",
        "\n",
        "print('average accuracy : ', np.mean(np.array(accuracies)))\n",
        "print('average loss : ', np.mean(np.array(losses)))\n",
        "print('average dicecoefs : ', np.mean(np.array(dicecoefs)))\n",
        "print('average ious : ', np.mean(np.array(ious)))\n",
        "print()\n",
        "\n",
        "print('standard deviation of accuracy : ', np.std(np.array(accuracies)))\n",
        "print('standard deviation of loss : ', np.std(np.array(losses)))\n",
        "print('standard deviation of dicecoefs : ', np.std(np.array(dicecoefs)))\n",
        "print('standard deviation of ious : ', np.std(np.array(ious)))"
      ],
      "metadata": {
        "id": "zplIbtdRUWH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    index=np.random.randint(0,len(test_data_frame.index))\n",
        "    print(i+1, index)\n",
        "    img = cv2.imread(test_data_frame['filename'].iloc[index])\n",
        "    img = cv2.resize(img, (height, width))\n",
        "    img = preprocess_input(img)\n",
        "    img = img[np.newaxis, :, :, :]\n",
        "    pred = model.predict(img)\n",
        "    pre_pred = Model(model.inputs, model.get_layer('pre').output).predict(img)\n",
        "\n",
        "    m_ = np.array(cv2.resize(cv2.imread(test_data_frame['mask'].iloc[index], cv2.IMREAD_GRAYSCALE), (height, width)), dtype='uint8')\n",
        "    _, thresh = cv2.threshold(m_,127,255,0)\n",
        "    contours, _ = cv2.findContours(thresh, 1, 2)\n",
        "\n",
        "    bbox = np.zeros(shape=4)\n",
        "    if len(contours) > 0:\n",
        "        cnt = contours[0]\n",
        "        x,y,w,h = cv2.boundingRect(cnt)\n",
        "\n",
        "        bbox[:] = x, y, w, h\n",
        "\n",
        "#     Assuming height == width\n",
        "    bbox /= height\n",
        "\n",
        "    plt.figure(figsize=(12,12))\n",
        "    plt.subplot(1,6,1)\n",
        "    plt.imshow(cv2.resize(cv2.imread(test_data_frame['filename'].iloc[index]), (height, width)))\n",
        "    plt.title('Original Image')\n",
        "    plt.subplot(1,6,2)\n",
        "    plt.imshow(np.squeeze(cv2.resize(cv2.imread(test_data_frame['mask'].iloc[index]), (height, width))))\n",
        "    plt.title('Original Mask')\n",
        "    plt.subplot(1,6,3)\n",
        "    plt.imshow(np.squeeze(pre_pred) > .5)\n",
        "    plt.title('Pre-Prediction')\n",
        "    plt.subplot(1,6,4)\n",
        "    plt.imshow(np.squeeze(pred[0]) > .5)\n",
        "    plt.title('Prediction')\n",
        "    x, y, w, h = np.array(bbox * height, dtype='int')\n",
        "    bb = cv2.resize(cv2.imread(test_data_frame['filename'].iloc[index], cv2.IMREAD_GRAYSCALE), (height, width))\n",
        "    bb = cv2.rectangle(bb, (x, y), (x+w, y+h), 1, 2)\n",
        "    plt.subplot(1,6,5)\n",
        "    plt.imshow(bb)\n",
        "    plt.title('BBox_original')\n",
        "    x, y, w, h = np.array(pred[2][0] * height, dtype='int')\n",
        "    print(pred[1],x,y,w,h)\n",
        "    bb = cv2.resize(cv2.imread(test_data_frame['filename'].iloc[index], cv2.IMREAD_GRAYSCALE), (height, width))\n",
        "    bb = cv2.rectangle(bb, (x, y), (x+w, y+h), 1, 2)\n",
        "    plt.subplot(1,6,6)\n",
        "    plt.imshow(bb)\n",
        "    plt.title('BBox')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "FIXCcOw1YM6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tp_cls = tp_seg = tn_cls = tn_seg = fp_cls = fp_seg = fn_cls = fn_seg = tp_mod = tn_mod = fp_mod = fn_mod = 0\n",
        "conf = np.zeros((2, 2, 2))\n",
        "conf2 = np.zeros((2, 2, 2))\n",
        "\n",
        "false_negatives = []\n",
        "false_positives = []\n",
        "\n",
        "# Debug: Limit processing to first 100 images (adjust as needed)\n",
        "MAX_IMAGES = 100\n",
        "train_data = list(zip(train_image_polished, train_mask_polished))[:MAX_IMAGES]\n",
        "\n",
        "for idx, (image_path, mask_path) in enumerate(tqdm(train_data, desc=\"Processing Images\")):\n",
        "    # Read images\n",
        "    img = cv2.imread(image_path)\n",
        "    mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Ensure grayscale mask\n",
        "\n",
        "    # Handle read errors\n",
        "    if img is None or mask_img is None:\n",
        "        print(f\"Skipping {image_path} or {mask_path} due to read error\")\n",
        "        continue\n",
        "\n",
        "    # Resize and preprocess input\n",
        "    img = cv2.resize(img, (height, width))\n",
        "    img = preprocess_input(img)\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Model predictions\n",
        "    pred = model.predict(img)\n",
        "    pre_pred = Model(model.inputs, model.get_layer('pre').output).predict(img)\n",
        "\n",
        "    # Ensure correct indexing and thresholding\n",
        "    ground_truth = 1 if np.sum(mask_img >= 128) > 0 else 0  # Adjusted threshold\n",
        "    cls_pred = 1 if pred[1] >= 0.5 else 0\n",
        "    seg_pred = 1 if np.sum(pred[0] >= 0.5) > 0 else 0\n",
        "    seg_pre_pred = 1 if np.sum(pre_pred[0] >= 0.5) > 0 else 0\n",
        "\n",
        "    # Update classification counts\n",
        "    if ground_truth == 1:\n",
        "        if cls_pred == 1:\n",
        "            tp_cls += 1\n",
        "        else:\n",
        "            fn_cls += 1\n",
        "    else:\n",
        "        if cls_pred == 0:\n",
        "            tn_cls += 1\n",
        "        else:\n",
        "            fp_cls += 1\n",
        "\n",
        "    # Update segmentation counts\n",
        "    if ground_truth == 1:\n",
        "        if seg_pred == 1:\n",
        "            tp_seg += 1\n",
        "        else:\n",
        "            fn_seg += 1\n",
        "    else:\n",
        "        if seg_pred == 0:\n",
        "            tn_seg += 1\n",
        "        else:\n",
        "            fp_seg += 1\n",
        "\n",
        "    # Update combined model counts\n",
        "    if cls_pred == 1 and seg_pred == 1:\n",
        "        tp_mod += 1\n",
        "    elif cls_pred == 0 and seg_pred == 0:\n",
        "        tn_mod += 1\n",
        "    elif cls_pred == 1 and seg_pred == 0:\n",
        "        fn_mod += 1\n",
        "        false_negatives.append((image_path, mask_path))\n",
        "    else:\n",
        "        fp_mod += 1\n",
        "\n",
        "    # Track false positives\n",
        "    if seg_pre_pred == 1 and cls_pred == 0:\n",
        "        false_positives.append((image_path, mask_path))\n",
        "\n",
        "    # Update confusion matrices\n",
        "    conf[ground_truth, cls_pred, seg_pred] += 1\n",
        "    conf2[ground_truth, cls_pred, seg_pre_pred] += 1\n",
        "\n",
        "    # Debug progress every 10 images\n",
        "    if idx % 10 == 0:\n",
        "        print(f\"[{idx}/{MAX_IMAGES}] Processed {image_path}\")\n",
        "\n",
        "print(\"Processing complete!\")"
      ],
      "metadata": {
        "id": "3Gx0C8ZTYaDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Modes\\t', 'TP', 'TN', 'FP', 'FN', sep='\\t')\n",
        "print('Class\\t', tp_cls, tn_cls, fp_cls, fn_cls, sep='\\t')\n",
        "print('Seg\\t', tp_seg, tn_seg, fp_seg, fn_seg, sep='\\t')\n",
        "print('Seg wrt Class', tp_mod, tn_mod, fp_mod, fn_mod, sep='\\t')"
      ],
      "metadata": {
        "id": "MUTNM6LwaRLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Pos examples:\\n')\n",
        "print(conf[1])\n",
        "print('Neg exaples:\\n')\n",
        "print(conf[0])"
      ],
      "metadata": {
        "id": "mhFNTLakaUhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Pos examples:\\n')\n",
        "print(conf2[1])\n",
        "print('Neg exaples:\\n')\n",
        "print(conf2[0])"
      ],
      "metadata": {
        "id": "644wF_RQaW6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r generated"
      ],
      "metadata": {
        "id": "smRgiNWJaY_T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}